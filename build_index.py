# build_index.py  (CSV only, cosine, batch-encode)
import os, csv, re
from pathlib import Path
from typing import List, Dict, Tuple

import chromadb
from sentence_transformers import SentenceTransformer

# ---- paths / constants ----
DATA_DIR    = Path("data")
CSV_PATH    = DATA_DIR / "faq.csv"                 # à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ: Question, Answer
INDEX_PATH  = os.getenv("INDEX_PATH", "index")
COLL_NAME   = os.getenv("COLL_NAME", "fit_faq")

EMB_MODEL      = os.getenv("EMB_MODEL", "all-MiniLM-L6-v2")
EMBED_BATCH    = int(os.getenv("EMBED_BATCH", 64))         # à¸¥à¸”à¹€à¸›à¹‡à¸™ 32 à¸–à¹‰à¸² RAM à¸™à¹‰à¸­à¸¢
NORMALIZE_EMB  = os.getenv("NORMALIZE_EMB", "1") == "1"    # à¹ƒà¸Šà¹‰ normalization

# ---- init ----
client   = chromadb.PersistentClient(path=INDEX_PATH)
embedder = SentenceTransformer(EMB_MODEL)

def clean_text(s: str) -> str:
    s = s.replace("\u00ad", "")                 # soft hyphen
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n{2,}", "\n\n", s)
    return s.strip()

def load_csv_faq(path: Path) -> List[Tuple[str, Dict]]:
    """
    à¸„à¸·à¸™à¸„à¹ˆà¸² list à¸‚à¸­à¸‡ (document_text, meta)
    document_text = Question + 2 newlines + Answer   <-- à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰ retrieval à¹à¸¡à¹ˆà¸™à¸‚à¸¶à¹‰à¸™
    meta['question'] à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¹ƒà¸Šà¹‰à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡ [Q#] à¸•à¸­à¸™à¸•à¸­à¸š
    """
    if not path.exists():
        raise FileNotFoundError(f"CSV not found: {path}")

    rows: List[Tuple[str, Dict]] = []
    with path.open("r", encoding="utf-8") as f:
        rdr = csv.DictReader(f)
        if not {"Question", "Answer"}.issubset(rdr.fieldnames or []):
            raise ValueError("CSV must contain 'Question' and 'Answer' columns.")

        for r in rdr:
            q = clean_text((r.get("Question") or "").strip())
            a = clean_text((r.get("Answer") or "").strip())
            if not q or not a:
                continue
            doc = f"{q}\n\n{a}"                                  # << à¸£à¸§à¸¡ Q + A
            rows.append((doc, {"source": path.name, "question": q, "type": "faq"}))
    return rows

def main():
    print(f"ðŸ§¹ Recreating collection at '{INDEX_PATH}' â€¦")
    try:
        client.delete_collection(name=COLL_NAME)
    except Exception:
        pass

    # à¸šà¸±à¸‡à¸„à¸±à¸š cosine à¹€à¸ªà¸¡à¸­ (à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¸„à¸¹à¹ˆà¸à¸±à¸š retrieval.py)
    coll = client.get_or_create_collection(
        name=COLL_NAME,
        metadata={"hnsw:space": "cosine"}
    )

    items = load_csv_faq(CSV_PATH)
    if not items:
        print("âš ï¸ No rows found in CSV.")
        return

    docs  = [t for t, _ in items]
    metas = [m for _, m in items]
    ids   = [f"csv-{i+1}" for i in range(len(items))]

    print(f"ðŸ“„ CSV rows: {len(items)}")
    print(f"ðŸ§  Embedding with {EMB_MODEL} (batch={EMBED_BATCH}) â€¦")

    # ---- batch embeddings ----
    embs: List[List[float]] = []
    for i in range(0, len(docs), EMBED_BATCH):
        batch = docs[i:i+EMBED_BATCH]
        vecs = embedder.encode(
            batch,
            normalize_embeddings=NORMALIZE_EMB,
            show_progress_bar=False,
        )
        # SentenceTransformer à¸„à¸·à¸™à¹€à¸›à¹‡à¸™ np.array â†’ à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ list
        embs.extend(vecs.tolist())

    # ---- upsert ----
    coll.add(documents=docs, metadatas=metas, ids=ids, embeddings=embs)

    # à¸•à¸£à¸§à¸ˆà¸™à¸±à¸šà¸£à¸²à¸¢à¸à¸²à¸£à¸ˆà¸£à¸´à¸‡
    try:
        n = coll.count()
        print(f"âœ… Index built at ./{INDEX_PATH} with {n} items")
    except Exception:
        print(f"âœ… Index built at ./{INDEX_PATH} with {len(docs)} items")

if __name__ == "__main__":
    main()